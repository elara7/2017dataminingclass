---
title: "Homework of Dataminning, CH6"
author: "Zexian Wang, Student ID 15420151152805"
date: "2017-03-31"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Q8

(a)

```{r}
set.seed(1234)
n <- 100
x <- rnorm(100)
e <- rnorm(100)
```

(b)

```{r}
X <- as.matrix(cbind(rep(1,n), x, x^2, x^3))
colnames(X) <- c("intercept", "x1", "x2", "x3")
beta <- c(1,2,3,4)
Y <- X %*% beta + e
```

(c)

```{r}
library(leaps)
d <- 10
data <- as.data.frame(cbind(Y, poly(x,degree = d,raw = T)))
names(data) <- c('Y',paste0("X",1:d))
```

best subset

```{r}
bestsubset <- regsubsets(Y~., data, nvmax = 10)
bestsubset_summary <- summary(bestsubset)

par(mfrow = c(1,3))
plot(bestsubset_summary$cp,type = "l",xlab = "number of variable", ylab = "cp", main = "cp")
whichcp <- which.min(bestsubset_summary$cp)
points(whichcp, bestsubset_summary$cp[whichcp], col = "red")

plot(bestsubset_summary$bic,type = "l",xlab = "number of variable", ylab = "bic", main = "bic")
whichbic <- which.min(bestsubset_summary$bic)
points(whichbic, bestsubset_summary$bic[whichbic], col = "red")

plot(bestsubset_summary$adjr2,type = "l",xlab = "number of variable", ylab = "adjr2", main = "adjr2")
whichadjr2 <- which.max(bestsubset_summary$adjr2)
points(whichadjr2, bestsubset_summary$adjr2[whichadjr2], col = "red")

# based on Cp
whichcp
coef(bestsubset,whichcp)
# based on BIC
whichbic
coef(bestsubset,whichbic)
# based on adjR2
whichadjr2
coef(bestsubset,whichadjr2)
```

(d)

forward

```{r}
fw <- regsubsets(Y~., data, method = "forward")
summaryfw <- summary(fw)

par(mfrow = c(1,3))
plot(summaryfw$cp,type = "l",xlab = "number of variable", ylab = "cp", main = "cp")
whichcp <- which.min(summaryfw$cp)
points(whichcp, summaryfw$cp[whichcp], col = "red")

plot(summaryfw$bic,type = "l",xlab = "number of variable", ylab = "bic", main = "bic")
whichbic <- which.min(summaryfw$bic)
points(whichbic, summaryfw$bic[whichbic], col = "red")

plot(summaryfw$adjr2,type = "l",xlab = "number of variable", ylab = "adjr2", main = "adjr2")
whichadjr2 <- which.max(summaryfw$adjr2)
points(whichadjr2, summaryfw$adjr2[whichadjr2], col = "red")

# based on Cp
whichcp
coef(fw,whichcp)
# based on BIC
whichbic
coef(fw,whichbic)
# based on adjR2
whichadjr2
coef(fw,whichadjr2)
```

backward

```{r}
bw <- regsubsets(Y~., data, method = "backward")
summarybw <- summary(bw)

par(mfrow = c(1,3))
plot(summarybw$cp,type = "l",xlab = "number of variable", ylab = "cp", main = "cp")
whichcp <- which.min(summarybw$cp)
points(whichcp, summarybw$cp[whichcp], col = "red")

plot(summarybw$bic,type = "l",xlab = "number of variable", ylab = "bic", main = "bic")
whichbic <- which.min(summarybw$bic)
points(whichbic, summarybw$bic[whichbic], col = "red")

plot(summarybw$adjr2,type = "l",xlab = "number of variable", ylab = "adjr2", main = "adjr2")
whichadjr2 <- which.max(summarybw$adjr2)
points(whichadjr2, summarybw$adjr2[whichadjr2], col = "red")

# based on Cp
whichcp
coef(bw,whichcp)
# based on BIC
whichbic
coef(bw,whichbic)
# based on adjR2
whichadjr2
coef(bw,whichadjr2)
```

All the model choose the right model.

(e)

```{r}
par(mfrow = c(1,1))
library(glmnet)
modelx <- model.matrix(Y~., data)[,-1]
modely <- data$Y
modellasso <- cv.glmnet(modelx, modely, alpha = 1)
plot(modellasso)
coef(modellasso)
```

Lasso model also choose the right variables.

(f)

```{r}
beta7 <- 5
Y = rep(beta[1],n) + beta7*x^7 + e
data$Y <- Y

```

best subset

```{r}
bestsubset <- regsubsets(Y~., data)
bestsubset_summary <- summary(bestsubset)

par(mfrow = c(1,3))
plot(bestsubset_summary$cp,type = "l",xlab = "number of variable", ylab = "cp", main = "cp")
whichcp <- which.min(bestsubset_summary$cp)
points(whichcp, bestsubset_summary$cp[whichcp], col = "red")

plot(bestsubset_summary$bic,type = "l",xlab = "number of variable", ylab = "bic", main = "bic")
whichbic <- which.min(bestsubset_summary$bic)
points(whichbic, bestsubset_summary$bic[whichbic], col = "red")

plot(bestsubset_summary$adjr2,type = "l",xlab = "number of variable", ylab = "adjr2", main = "adjr2")
whichadjr2 <- which.max(bestsubset_summary$adjr2)
points(whichadjr2, bestsubset_summary$adjr2[whichadjr2], col = "red")

# based on Cp
whichcp
coef(bestsubset,whichcp)
# based on BIC
whichbic
coef(bestsubset,whichbic)
# based on adjR2
whichadjr2
coef(bestsubset,whichadjr2)
```

lasso

```{r}
par(mfrow = c(1,1))
library(glmnet)
modelx <- model.matrix(Y~., data)[,-1]
modely <- data$Y
modellasso <- cv.glmnet(modelx, modely, alpha = 1)
plot(modellasso)
coef(modellasso)
```

Only the best subset selection with adjR2 choose the wrong variable X2

# Q9

(a)

```{r}
library(ISLR)
n = nrow(College)
set.seed(1)
College <- College[,c("Apps",names(College)[-2])]
trainindex <- sample(n, n/3*2,replace = F)
train <- College[trainindex,]
test <- College[-trainindex,]
```

(b)

LS

```{r}
modellm <- lm(Apps~.,train)
mean((predict(modellm,newdata = test[,-1])-test$Apps)^2)
```

(c)

Ridge

```{r}
library(glmnet)
trainx <- model.matrix(Apps~., train)[,-1]
testx <- model.matrix(Apps~.,test)[,-1]
trainy <- train$Apps
modelridge <- cv.glmnet(trainx, trainy, alpha = 0)
mean((predict(modelridge,newx = testx)-test$Apps)^2)
```

(d)

Lasso 

```{r}

trainx <- model.matrix(Apps~., train)[,-1]
testx <- model.matrix(Apps~.,test)[,-1]
trainy <- train$Apps
modellasso <- cv.glmnet(trainx, trainy, alpha = 1)
mean((predict(modellasso,newx = testx)-test$Apps)^2)
sum(coef(modellasso)!=0)
```

(e)

PCR

```{r}
library(pls)
set.seed(1)
pcr.fit <- pcr(Apps~., data=train, scale = T, validation = "CV")
validationplot(pcr.fit)
summary(pcr.fit)
```

The best M is 17.

```{r}
predictpcr <- predict(pcr.fit, test[,-1], ncomp = 17)
mean((predictpcr - test$Apps)^2)
```

(f)

PLS

```{r}
set.seed(1)
pls.fit <- plsr(Apps~., data = train, scale = T, validation = "CV")
validationplot(pls.fit)
summary(pls.fit)
```

The best M is 9.

```{r}
predictpls <- predict(pls.fit, test[,-1], ncomp = 9)
mean((predictpls - test$Apps)^2)
```

(g)

The MSE of these models are: LS

LS:925316.1

Ridge:1260720

Lasso:1298099

PCR:925316.1

PLS:931713.9

The best model is PCR with 17 compents and Least Square. The worest model is Lasso. However, there are not very obvious difference between these MSEs.
